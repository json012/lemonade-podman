---
- name: Lemonade via LiteLLM stack (Docker Compose)
  hosts: all
  connection: "{{ 'local' if inventory_hostname == 'localhost' else 'ssh' }}"
  gather_facts: true

  vars:
    project_root: "./"

  pre_tasks:
    - name: Display deployment target
      debug:
        msg: |
          ğŸ“ Deploying to: {{ inventory_hostname }}
          Connection: {{ 'local' if inventory_hostname == 'localhost' else 'ssh' }}
      run_once: true
      tags: always

    - name: Set enable_online_hosting with default
      set_fact:
        enable_online_hosting: "{{ enable_online_hosting | default(false) }}"

    - name: Set use_systemd with default
      set_fact:
        use_systemd: "{{ use_systemd | default(false) }}"

    - name: Set add_rag with default
      set_fact:
        add_rag: "{{ add_rag | default(false) }}"

    - name: Set compose files based on deployment type
      set_fact:
        compose_files: >-
          {{
            ['docker-compose.yml', 'docker-compose.proxied-models.yml'] +
            (['docker-compose.online.yml'] if enable_online_hosting else []) +
            (['docker-compose.pgvector.yml'] if add_rag else [])
          }}

    - name: Derive deployment directory
      set_fact:
        deployment_dir: "{{ deployment_dir | default(ansible_env.HOME + '/.config/lemonade') }}"

    - name: Set required files based on deployment type
      set_fact:
        required_files: >-
          {{
            ['.env', 'docker-compose.yml', 'docker-compose.proxied-models.yml', 'litellm.yaml'] +
            (['docker-compose.online.yml', 'traefik-hosts.yaml', 'traefik.yaml'] if enable_online_hosting else []) +
            (['docker-compose.pgvector.yml'] if add_rag else [])
          }}

    - name: Check if required configuration files exist locally
      stat:
        path: "{{ item }}"
      loop: "{{ required_files }}"
      register: required_files_check
      delegate_to: localhost

    - name: Fail if required files are missing
      fail:
        msg: |
          âŒ MISSING CONFIGURATION FILES
          
          The following files are required but not found:
          {% for result in required_files_check.results %}
          {% if not result.stat.exists %}
          â€¢ {{ result.item }}
          {% endif %}
          {% endfor %}
          
          ğŸ“‹ SETUP INSTRUCTIONS:
          1. Copy sample.env to .env and configure your values
          2. Copy litellm.example.yaml to litellm.yaml and configure as needed
          3. Copy docker-compose.proxied-models.example.yml to docker-compose.proxied-models.yml

          For steps 2 and 3, you can use the generate_model_configs.sh script to automatically create
          litellm.yaml and docker-compose.proxied-models.yml files based on models you choose:
          ./generate_model_configs.sh
          {% if enable_online_hosting %}
          4. Copy traefik-hosts.example.yaml to traefik-hosts.yaml and configure your domain
          {% endif %}
      when: required_files_check.results | selectattr('stat.exists', 'equalto', false) | list | length > 0

    - name: Set required environment variables
      set_fact:
        required_env_vars: >-
          {{
            ['LITELLM_MASTER_KEY', 'LITELLM_SALT_KEY', 'LITELLM_HOST', 'POSTGRES_DB', 'POSTGRES_USER', 'POSTGRES_PASSWORD'] +
            (['TUNNEL_TOKEN'] if enable_online_hosting else []) +
            (['RAG_DB_NAME', 'RAG_DB_USER', 'RAG_DB_PASS', 'RAG_SERVER_API_KEY', 'RAG_SERVER_HOST'] if add_rag else [])
          }}

    - name: Check each environment variable individually
      shell: "grep -q '^{{ item }}=' .env"
      loop: "{{ required_env_vars }}"
      register: env_var_checks
      failed_when: false
      delegate_to: localhost

    - name: Set missing environment variables
      set_fact:
        missing_env_vars: >-
          {{
            required_env_vars | zip(env_var_checks.results) | 
            selectattr('1.rc', 'ne', 0) | map(attribute='0') | list
          }}

    - name: Fail if environment variables are missing
      fail:
        msg: |
          âŒ MISSING ENVIRONMENT VARIABLES
          
          The following variables are required in your .env file but not found:
          {% for var in missing_env_vars %}
          â€¢ {{ var }}
          {% endfor %}
          
          ğŸ“‹ Please add these variables to your .env file with appropriate values.
      when: missing_env_vars | length > 0


    - name: Ensure deployment directory exists
      file:
        path: "{{ deployment_dir }}"
        state: directory
        mode: "0755"

    - name: Check if required packages are available
      command: "which {{ item }}"
      loop:
        - "podman"
        - "podman-compose"
      register: package_check
      failed_when: package_check.rc != 0
      changed_when: false

    - name: Fail if required packages are missing
      fail:
        msg: |
          âŒ MISSING REQUIRED PACKAGES
          
          The following packages are required but not found:
          {% for result in package_check.results %}
          {% if result.rc != 0 %}
          â€¢ {{ result.item }}
          {% endif %}
          {% endfor %}
          
          ğŸ“‹ Install them with your package manager:
          sudo dnf install podman
          # or
          sudo apt install podman
      when: package_check.results | selectattr('rc', 'ne', 0) | list | length > 0

    - name: Check if git is available
      command: "which git"
      register: git_check
      failed_when: git_check.rc != 0
      changed_when: false

    - name: Fail if git is missing
      fail:
        msg: |
          âŒ MISSING GIT
          
          Git is required to handle submodules but not found.
          
          ğŸ“‹ Install git with your package manager:
          sudo dnf install git
          # or
          sudo apt install git
      when: git_check.rc != 0

    - name: Initialize git submodules
      shell: "cd {{ project_root }} && git submodule update --init --recursive"
      register: submodule_init_result
      delegate_to: localhost

    - name: Display submodule initialization result
      debug:
        var: submodule_init_result.stdout_lines

  tasks:
    - name: Copy .env file from project root to user vars directory
      copy:
        src: "{{ project_root }}/.env"
        dest: "{{ deployment_dir }}/.env"
        mode: "0644"

    - name: Copy docker-compose files to target host
      copy:
        src: "{{ project_root }}/{{ item }}"
        dest: "{{ deployment_dir }}/{{ item }}"
        mode: "0644"
      loop: "{{ compose_files }}"

    - name: Copy litellm.yaml to target host
      copy:
        src: "{{ project_root }}/litellm.yaml"
        dest: "{{ deployment_dir }}/litellm.yaml"
        mode: "0644"

    - name: Copy traefik configuration files (if online hosting)
      copy:
        src: "{{ project_root }}/{{ item }}"
        dest: "{{ deployment_dir }}/{{ item }}"
        mode: "0644"
      loop:
        - "traefik.yaml"
        - "traefik-hosts.yaml"
      when: enable_online_hosting

    - name: Copy litellm-pgvector submodule to target host
      copy:
        src: "{{ project_root }}/litellm-pgvector/"
        dest: "{{ deployment_dir }}/litellm-pgvector/"
        mode: "0644"
      when: add_rag

    - name: Copy postgres directory to target host
      copy:
        src: "{{ project_root }}/pg-vector/"
        dest: "{{ deployment_dir }}/pg-vector/"
        mode: "0644"
      when: add_rag

    - name: Get current user ID
      shell: id -u
      register: current_user_id
      changed_when: false

    - name: Update socket path in docker-compose.online.yml for current user
      replace:
        path: "{{ deployment_dir }}/docker-compose.online.yml"
        regexp: '/run/user/1000/podman/podman.sock'
        replace: '/run/user/{{ current_user_id.stdout }}/podman/podman.sock'
      when: enable_online_hosting and current_user_id.stdout != '1000'

    - name: Stop existing containers
      shell: "cd {{ deployment_dir }} && podman compose -f docker-compose.yml -f docker-compose.proxied-models.yml{% if enable_online_hosting %} -f docker-compose.online.yml{% endif %}{% if add_rag %} -f docker-compose.pgvector.yml{% endif %} down"
      ignore_errors: true

    - name: Start containers with podman compose
      shell: "cd {{ deployment_dir }} && podman compose -f docker-compose.yml -f docker-compose.proxied-models.yml{% if enable_online_hosting %} -f docker-compose.online.yml{% endif %}{% if add_rag %} -f docker-compose.pgvector.yml{% endif %} up -d"
      register: compose_start_result

    - name: Display compose start result
      debug:
        var: compose_start_result.stdout_lines

    - name: Wait for LiteLLM to be ready
      shell: "curl -f http://localhost:4000/health/liveliness"
      register: litellm_health
      until: litellm_health.rc == 0
      retries: 30
      delay: 10
      when: add_rag
      changed_when: false

    - name: Check if LITELLM_RAG_EMBEDDING_API_KEY already exists in .env file
      shell: "grep '^LITELLM_RAG_EMBEDDING_API_KEY=' {{ deployment_dir }}/.env | cut -d'=' -f2-"
      register: existing_rag_api_key
      when: add_rag
      failed_when: false
      changed_when: false

    - name: Read LITELLM_MASTER_KEY from .env file
      shell: "grep '^LITELLM_MASTER_KEY=' {{ deployment_dir }}/.env | cut -d'=' -f2-"
      register: master_key_result
      when: add_rag and (existing_rag_api_key.stdout is not defined or existing_rag_api_key.stdout | length == 0)
      changed_when: false

    - name: Generate API key for embedding model
      shell: |
        curl -s -X POST 'http://localhost:4000/key/generate' \
          -H 'Authorization: Bearer {{ master_key_result.stdout }}' \
          -H 'Content-Type: application/json' \
          -d '{
            "models": ["nomic-embed-text-v2-moe-GGUF"],
            "key_alias": "rag_embedding_key"
          }'
      register: api_key_response
      when: add_rag and (existing_rag_api_key.stdout is not defined or existing_rag_api_key.stdout | length == 0)
      failed_when: false
      changed_when: false

    - name: Display API key response for debugging
      debug:
        var: api_key_response.stdout
      when: add_rag and (existing_rag_api_key.stdout is not defined or existing_rag_api_key.stdout | length == 0) and api_key_response.stdout is defined

    - name: Check if API key generation returned an error
      set_fact:
        api_key_generation_failed: "{{ (api_key_response.stdout | from_json).error is defined }}"
      when: add_rag and (existing_rag_api_key.stdout is not defined or existing_rag_api_key.stdout | length == 0) and api_key_response.stdout is defined and api_key_response.stdout | length > 0

    - name: Display warning if key already exists in LiteLLM
      debug:
        msg: "âš ï¸  API key with alias 'rag_embedding_key' already exists in LiteLLM. Deleting and recreating it..."
      when: add_rag and api_key_generation_failed is defined and api_key_generation_failed

    - name: Delete existing API key by alias
      shell: |
        curl -s -X POST 'http://localhost:4000/key/delete' \
          -H 'Authorization: Bearer {{ master_key_result.stdout }}' \
          -H 'Content-Type: application/json' \
          -d '{"key_aliases": ["rag_embedding_key"]}'
      when: add_rag and api_key_generation_failed is defined and api_key_generation_failed
      failed_when: false
      changed_when: false

    - name: Regenerate API key after deletion
      shell: |
        curl -s -X POST 'http://localhost:4000/key/generate' \
          -H 'Authorization: Bearer {{ master_key_result.stdout }}' \
          -H 'Content-Type: application/json' \
          -d '{
            "models": ["nomic-embed-text-v2-moe-GGUF"],
            "key_alias": "rag_embedding_key"
          }'
      register: regenerated_api_key_response
      when: add_rag and api_key_generation_failed is defined and api_key_generation_failed
      failed_when: false
      changed_when: false

    - name: Extract regenerated API key from response
      set_fact:
        generated_api_key: "{{ (regenerated_api_key_response.stdout | from_json).key | default((regenerated_api_key_response.stdout | from_json).token) }}"
      when: add_rag and api_key_generation_failed is defined and api_key_generation_failed and regenerated_api_key_response.stdout is defined

    - name: Extract API key from response
      set_fact:
        generated_api_key: "{{ (api_key_response.stdout | from_json).key | default((api_key_response.stdout | from_json).token) }}"
      when: add_rag and (existing_rag_api_key.stdout is not defined or existing_rag_api_key.stdout | length == 0) and api_key_response.stdout is defined and api_key_response.stdout | length > 0 and (api_key_generation_failed is not defined or not api_key_generation_failed)

    - name: Update .env file with generated API key
      lineinfile:
        path: "{{ deployment_dir }}/.env"
        regexp: '^LITELLM_RAG_EMBEDDING_API_KEY='
        line: "LITELLM_RAG_EMBEDDING_API_KEY={{ generated_api_key }}"
      when: add_rag and generated_api_key is defined

    - name: Restart pgvector container to use new API key
      shell: "cd {{ deployment_dir }} && podman compose -f docker-compose.yml -f docker-compose.proxied-models.yml{% if enable_online_hosting %} -f docker-compose.online.yml{% endif %} -f docker-compose.pgvector.yml restart litellm-pgvector"
      when: add_rag and generated_api_key is defined

    - name: Show running containers
      shell: "podman ps --format 'table {{ \"{{.Names}}\" }}\t{{ \"{{.Status}}\" }}\t{{ \"{{.Ports}}\" }}'"
      register: running_containers

    - name: Display running containers
      debug:
        var: running_containers.stdout_lines

    - name: Create user systemd service directories
      file:
        path: "{{ item }}"
        state: directory
        mode: "0755"
      loop:
        - "{{ ansible_env.HOME }}/.config/systemd/user"
        - "{{ ansible_env.HOME }}/.config/containers/compose/projects"
      when: use_systemd

    - name: Register compose project with systemd
      shell: "cd {{ deployment_dir }} && podman compose -f docker-compose.yml -f docker-compose.proxied-models.yml{% if enable_online_hosting %} -f docker-compose.online.yml{% endif %}{% if add_rag %} -f docker-compose.pgvector.yml{% endif %} systemd --action register"
      register: systemd_register_result
      when: use_systemd

    - name: Display systemd registration result
      debug:
        var: systemd_register_result.stdout_lines
      when: use_systemd

    - name: Create and save systemd unit file
      shell: "cd {{ deployment_dir }} && podman compose -f docker-compose.yml -f docker-compose.proxied-models.yml{% if enable_online_hosting %} -f docker-compose.online.yml{% endif %}{% if add_rag %} -f docker-compose.pgvector.yml{% endif %} systemd --action create-unit > '{{ ansible_env.HOME }}/.config/systemd/user/podman-compose@.service'"
      when: use_systemd

    - name: Reload user systemd daemon
      shell: "systemctl --user daemon-reload"
      when: use_systemd

    - name: Enable systemd service
      shell: "systemctl --user enable podman-compose@lemonade"
      when: use_systemd

    - name: Start systemd service
      shell: "systemctl --user start podman-compose@lemonade"
      register: systemd_service_result
      when: use_systemd

    - name: Display systemd service status
      shell: "systemctl --user status podman-compose@lemonade"
      register: systemd_status_result
      when: use_systemd

    - name: Show systemd service status
      debug:
        var: systemd_status_result.stdout_lines
      when: use_systemd

    - name: Display usage instructions
      debug:
        msg: |
          âœ… Docker Compose deployment completed!
          
          {% if use_systemd %}
          ğŸ”§ Systemd service management:
          User systemd service is created and enabled as podman-compose@lemonade.service
          
          View service status: systemctl --user status podman-compose@lemonade
          
          ğŸ“‹ Pod management commands:
          â€¢ View pod stats: podman pod stats pod_lemonade
          â€¢ View pod logs: podman pod logs --tail=10 -f pod_lemonade
          {% else %}
          ğŸ“‹ Management commands:
          â€¢ View logs: cd {{ deployment_dir }} && podman compose logs -f
          â€¢ Stop stack: cd {{ deployment_dir }} && podman compose down
          â€¢ Restart stack: cd {{ deployment_dir }} && podman compose restart
          {% endif %}
          
          {% if enable_online_hosting %}
          ğŸŒ Online hosting is enabled. Your LiteLLM instance should be accessible via your configured domain.
          {% else %}
          ğŸ  Local deployment. LiteLLM is accessible at http://localhost:4000
          {% endif %}
          
          {% if add_rag %}
          ğŸ” PGVector RAG support is enabled!
          â€¢ PGVector API is accessible at http://localhost:4001
          â€¢ Uses lemonade-nomic-embed-text-v2-moe-GGUF embedding model
          {% endif %}